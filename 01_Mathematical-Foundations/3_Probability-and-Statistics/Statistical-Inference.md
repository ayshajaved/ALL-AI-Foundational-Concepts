# Statistical Inference

> **Learning from data** - Estimation, confidence, and hypothesis testing

---

## ğŸ“Š Point Estimation

### Estimators

**Estimator:** Function of data that estimates parameter
```
Î¸Ì‚ = g(Xâ‚, Xâ‚‚, ..., Xâ‚™)
```

### Properties of Estimators

**1. Unbiased**
```
E[Î¸Ì‚] = Î¸
```

**2. Consistent**
```
Î¸Ì‚ â†’ Î¸ as n â†’ âˆ
```

**3. Efficient**
```
Minimum variance among unbiased estimators
```

---

## ğŸ¯ Maximum Likelihood Estimation (MLE)

### Definition
```
Î¸Ì‚_ML = argmax_Î¸ L(Î¸|data)
      = argmax_Î¸ P(data|Î¸)
```

### Log-Likelihood
```
â„“(Î¸) = log L(Î¸) = Î£áµ¢ log P(xáµ¢|Î¸)
```

### Example: Normal Distribution
```python
import numpy as np

# Data
data = np.random.randn(1000) * 2 + 5

# MLE for Î¼ and ÏƒÂ²
mu_mle = np.mean(data)
sigma2_mle = np.var(data, ddof=0)  # MLE uses n, not n-1

print(f"Î¼Ì‚ = {mu_mle:.3f}")
print(f"ÏƒÌ‚Â² = {sigma2_mle:.3f}")
```

---

## ğŸ“ˆ Confidence Intervals

### Definition
```
P(Î¸ âˆˆ [L, U]) = 1 - Î±

[L, U] is (1-Î±)Ã—100% confidence interval
```

**Common:** Î± = 0.05 â†’ 95% CI

### For Normal Distribution
```python
from scipy import stats

# Sample mean CI
data = np.random.randn(100)
mean = np.mean(data)
se = stats.sem(data)  # Standard error

# 95% CI
ci = stats.t.interval(0.95, len(data)-1, loc=mean, scale=se)
print(f"95% CI: [{ci[0]:.3f}, {ci[1]:.3f}]")
```

---

## ğŸ§ª Hypothesis Testing

### Framework

**Null hypothesis Hâ‚€:** Default assumption
**Alternative Hâ‚:** What we want to show

**Test statistic:** Measure of evidence against Hâ‚€
**p-value:** P(observe data | Hâ‚€ true)

**Decision:**
- p < Î±: Reject Hâ‚€
- p â‰¥ Î±: Fail to reject Hâ‚€

### t-Test

```python
from scipy.stats import ttest_1samp, ttest_ind

# One-sample t-test
# Hâ‚€: Î¼ = Î¼â‚€
data = np.random.randn(100) + 0.5
t_stat, p_value = ttest_1samp(data, 0)
print(f"t = {t_stat:.3f}, p = {p_value:.3f}")

# Two-sample t-test
# Hâ‚€: Î¼â‚ = Î¼â‚‚
group1 = np.random.randn(100)
group2 = np.random.randn(100) + 0.5
t_stat, p_value = ttest_ind(group1, group2)
print(f"t = {t_stat:.3f}, p = {p_value:.3f}")
```

---

## ğŸ“Š Bootstrap

### Idea
Resample data with replacement to estimate sampling distribution

```python
def bootstrap_ci(data, statistic=np.mean, n_bootstrap=10000, alpha=0.05):
    """Compute bootstrap confidence interval"""
    bootstrap_stats = []
    
    for _ in range(n_bootstrap):
        sample = np.random.choice(data, size=len(data), replace=True)
        bootstrap_stats.append(statistic(sample))
    
    lower = np.percentile(bootstrap_stats, 100*alpha/2)
    upper = np.percentile(bootstrap_stats, 100*(1-alpha/2))
    
    return lower, upper

# Example
data = np.random.randn(100)
ci = bootstrap_ci(data)
print(f"Bootstrap 95% CI: [{ci[0]:.3f}, {ci[1]:.3f}]")
```

---

## ğŸ¯ Central Limit Theorem

### Statement
```
XÌ„â‚™ = (Xâ‚ + ... + Xâ‚™)/n

As n â†’ âˆ:
XÌ„â‚™ ~ N(Î¼, ÏƒÂ²/n)
```

**Implications:**
- Sample mean is approximately normal
- Regardless of original distribution!
- Foundation of many statistical methods

```python
# Demonstration
from scipy.stats import expon

# Non-normal distribution (exponential)
samples = []
for _ in range(10000):
    sample = expon.rvs(size=30)  # n=30
    samples.append(np.mean(sample))

# Sample means are approximately normal!
plt.hist(samples, bins=50, density=True)
plt.title('Distribution of Sample Means (CLT)')
plt.show()
```

---

## ğŸ“ Interview Focus

### Key Questions

1. **What is MLE?**
   - Maximum likelihood estimation
   - Find parameters that maximize P(data|Î¸)
   - Asymptotically optimal

2. **Confidence interval interpretation?**
   - 95% CI: If we repeat experiment, 95% of CIs contain true Î¸
   - NOT: Î¸ has 95% probability of being in interval

3. **p-value meaning?**
   - P(observe data | Hâ‚€ true)
   - NOT: P(Hâ‚€ true | data)
   - Small p-value = evidence against Hâ‚€

4. **Central Limit Theorem?**
   - Sample mean â†’ Normal as n increases
   - Works for any distribution
   - Foundation of inference

5. **Bootstrap vs analytical CI?**
   - Bootstrap: resampling, no assumptions
   - Analytical: assumes distribution
   - Bootstrap more general

---

## ğŸ“š References

- **Books:** "Statistical Inference" - Casella & Berger
- **Online:** Khan Academy Statistics

---

**Statistical inference: learning from data with rigor!**
