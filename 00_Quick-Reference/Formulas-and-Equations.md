# Essential AI Formulas & Equations

> **Mathematical reference for AI/ML** - All critical formulas organized by topic

---

## ğŸ“Š Statistics & Probability

### Basic Statistics
```
Mean: Î¼ = (1/n) Î£ x_i
Variance: ÏƒÂ² = (1/n) Î£ (x_i - Î¼)Â²
Standard Deviation: Ïƒ = âˆšÏƒÂ²
Covariance: Cov(X,Y) = E[(X-Î¼_X)(Y-Î¼_Y)]
Correlation: Ï = Cov(X,Y) / (Ïƒ_X Ïƒ_Y)
```

### Probability
```
Bayes' Theorem: P(A|B) = P(B|A)P(A) / P(B)
Chain Rule: P(A,B,C) = P(A|B,C)P(B|C)P(C)
Law of Total Probability: P(A) = Î£ P(A|B_i)P(B_i)
```

### Distributions
```
Gaussian/Normal: p(x) = (1/âˆš(2Ï€ÏƒÂ²)) exp(-(x-Î¼)Â²/(2ÏƒÂ²))
Bernoulli: P(X=1) = p, P(X=0) = 1-p
Binomial: P(X=k) = C(n,k) p^k (1-p)^(n-k)
```

---

## ğŸ§® Linear Algebra

### Matrix Operations
```
Matrix Multiplication: (AB)_ij = Î£_k A_ik B_kj
Transpose: (A^T)_ij = A_ji
Inverse: AA^{-1} = I
Determinant: det(A) for square matrix A
Trace: tr(A) = Î£ A_ii
```

### Eigenvalues & Eigenvectors
```
Av = Î»v  (v: eigenvector, Î»: eigenvalue)
Characteristic Equation: det(A - Î»I) = 0
```

### SVD (Singular Value Decomposition)
```
A = UÎ£V^T
U: left singular vectors
Î£: singular values (diagonal)
V: right singular vectors
```

---

## ğŸ“ Calculus & Optimization

### Derivatives
```
Power Rule: d/dx(x^n) = nx^{n-1}
Chain Rule: d/dx f(g(x)) = f'(g(x))g'(x)
Product Rule: d/dx(fg) = f'g + fg'
Quotient Rule: d/dx(f/g) = (f'g - fg')/gÂ²
```

### Gradient
```
âˆ‡f = [âˆ‚f/âˆ‚xâ‚, âˆ‚f/âˆ‚xâ‚‚, ..., âˆ‚f/âˆ‚xâ‚™]^T
```

### Gradient Descent
```
w_{t+1} = w_t - Î·âˆ‡L(w_t)
Î·: learning rate
âˆ‡L: gradient of loss
```

---

## ğŸ§  Machine Learning

### Linear Regression
```
Model: y = XÎ² + Îµ
Normal Equation: Î² = (X^T X)^{-1} X^T y
Cost Function (MSE): J(Î²) = (1/2m) Î£(h_Î²(x^(i)) - y^(i))Â²
Gradient: âˆ‡J = (1/m) X^T(XÎ² - y)
```

### Logistic Regression
```
Sigmoid: Ïƒ(z) = 1/(1 + e^{-z})
Model: P(y=1|x) = Ïƒ(w^T x + b)
Cost Function: J = -(1/m) Î£[y log(Å·) + (1-y)log(1-Å·)]
Gradient: âˆ‡J = (1/m) X^T(Ïƒ(Xw) - y)
```

### Softmax
```
softmax(z_i) = e^{z_i} / Î£_j e^{z_j}
Cross-Entropy Loss: L = -Î£ y_i log(Å·_i)
```

### Regularization
```
L1 (Lasso): J = MSE + Î» Î£|w_i|
L2 (Ridge): J = MSE + Î» Î£w_iÂ²
Elastic Net: J = MSE + Î»â‚Î£|w_i| + Î»â‚‚Î£w_iÂ²
```

### SVM
```
Objective: min (1/2)||w||Â² subject to y_i(w^T x_i + b) â‰¥ 1
Kernel Trick: K(x,x') = Ï†(x)^T Ï†(x')
RBF Kernel: K(x,x') = exp(-Î³||x-x'||Â²)
```

### Decision Trees
```
Gini Impurity: Gini = 1 - Î£ p_iÂ²
Entropy: H = -Î£ p_i logâ‚‚(p_i)
Information Gain: IG = H(parent) - Î£(n_i/n)H(child_i)
```

### K-Means
```
Objective: min Î£_k Î£_{xâˆˆC_k} ||x - Î¼_k||Â²
Update: Î¼_k = (1/|C_k|) Î£_{xâˆˆC_k} x
```

### PCA
```
Maximize: var(Xw) = w^T Î£ w subject to ||w||=1
Solution: w = eigenvectors of covariance matrix Î£
```

---

## ğŸ”¥ Deep Learning

### Forward Propagation
```
z^{[l]} = W^{[l]} a^{[l-1]} + b^{[l]}
a^{[l]} = g^{[l]}(z^{[l]})
```

### Backpropagation
```
dL/dW^{[l]} = dL/da^{[l]} Â· da^{[l]}/dz^{[l]} Â· dz^{[l]}/dW^{[l]}
            = dL/da^{[l]} Â· g'^{[l]}(z^{[l]}) Â· a^{[l-1]T}
```

### Activation Functions
```
ReLU: f(x) = max(0, x)
       f'(x) = 1 if x>0, else 0

Leaky ReLU: f(x) = max(Î±x, x)  (Î±=0.01)

Sigmoid: Ïƒ(x) = 1/(1+e^{-x})
         Ïƒ'(x) = Ïƒ(x)(1-Ïƒ(x))

Tanh: tanh(x) = (e^x - e^{-x})/(e^x + e^{-x})
      tanh'(x) = 1 - tanhÂ²(x)

GELU: f(x) = xÂ·Î¦(x) where Î¦ is CDF of N(0,1)
```

### Loss Functions
```
MSE: L = (1/n) Î£(y - Å·)Â²
MAE: L = (1/n) Î£|y - Å·|
Binary Cross-Entropy: L = -[y log(Å·) + (1-y)log(1-Å·)]
Categorical Cross-Entropy: L = -Î£ y_i log(Å·_i)
Hinge Loss: L = max(0, 1 - yÂ·Å·)
```

### Optimizers
```
SGD: w = w - Î·âˆ‡L

Momentum: v = Î²v + âˆ‡L
          w = w - Î·v

RMSprop: s = Î²s + (1-Î²)âˆ‡LÂ²
         w = w - Î·âˆ‡L/âˆš(s+Îµ)

Adam: m = Î²â‚m + (1-Î²â‚)âˆ‡L
      v = Î²â‚‚v + (1-Î²â‚‚)âˆ‡LÂ²
      mÌ‚ = m/(1-Î²â‚^t)
      vÌ‚ = v/(1-Î²â‚‚^t)
      w = w - Î·Â·mÌ‚/âˆš(vÌ‚+Îµ)
```

### Batch Normalization
```
Î¼_B = (1/m) Î£ x_i
ÏƒÂ²_B = (1/m) Î£(x_i - Î¼_B)Â²
xÌ‚_i = (x_i - Î¼_B)/âˆš(ÏƒÂ²_B + Îµ)
y_i = Î³xÌ‚_i + Î²  (learnable Î³, Î²)
```

### Dropout
```
During Training: r ~ Bernoulli(p)
                 Å· = r * y / p
During Inference: Å· = y
```

---

## ğŸ–¼ï¸ Computer Vision

### Convolution
```
Output Size: O = (W - F + 2P)/S + 1
W: input width
F: filter size
P: padding
S: stride
```

### Receptive Field
```
RF_{l+1} = RF_l + (kernel_size - 1) Ã— stride_product
```

### IoU (Intersection over Union)
```
IoU = Area of Overlap / Area of Union
    = |A âˆ© B| / |A âˆª B|
```

---

## ğŸ’¬ NLP & Transformers

### Attention
```
Attention(Q,K,V) = softmax(QK^T/âˆšd_k)V
Q: Query matrix
K: Key matrix
V: Value matrix
d_k: dimension of keys (scaling factor)
```

### Multi-Head Attention
```
MultiHead(Q,K,V) = Concat(headâ‚,...,head_h)W^O
head_i = Attention(QW^Q_i, KW^K_i, VW^V_i)
```

### Positional Encoding
```
PE(pos,2i) = sin(pos/10000^{2i/d_model})
PE(pos,2i+1) = cos(pos/10000^{2i/d_model})
```

### Perplexity
```
PPL = exp(-(1/N)Î£ log P(w_i|context))
```

### BLEU Score
```
BLEU = BP Â· exp(Î£ w_n log p_n)
BP: brevity penalty
p_n: n-gram precision
```

---

## ğŸ® Reinforcement Learning

### Value Functions
```
V^Ï€(s) = E_Ï€[Î£ Î³^t R_t | S_0=s]
Q^Ï€(s,a) = E_Ï€[Î£ Î³^t R_t | S_0=s, A_0=a]
```

### Bellman Equations
```
V(s) = max_a [R(s,a) + Î³ Î£ P(s'|s,a)V(s')]
Q(s,a) = R(s,a) + Î³ Î£ P(s'|s,a) max_a' Q(s',a')
```

### Temporal Difference
```
V(S_t) â† V(S_t) + Î±[R_{t+1} + Î³V(S_{t+1}) - V(S_t)]
TD Error: Î´_t = R_{t+1} + Î³V(S_{t+1}) - V(S_t)
```

### Q-Learning
```
Q(S_t,A_t) â† Q(S_t,A_t) + Î±[R_{t+1} + Î³ max_a Q(S_{t+1},a) - Q(S_t,A_t)]
```

### Policy Gradient
```
âˆ‡_Î¸ J(Î¸) = E_Ï€[âˆ‡_Î¸ log Ï€_Î¸(a|s) Q^Ï€(s,a)]
REINFORCE: âˆ‡_Î¸ J(Î¸) â‰ˆ Î£ âˆ‡_Î¸ log Ï€_Î¸(a_t|s_t) G_t
```

### Advantage Function
```
A^Ï€(s,a) = Q^Ï€(s,a) - V^Ï€(s)
```

---

## ğŸ“Š Evaluation Metrics

### Classification
```
Accuracy = (TP + TN)/(TP + TN + FP + FN)
Precision = TP/(TP + FP)
Recall = TP/(TP + FN)
F1 = 2Â·(PrecisionÂ·Recall)/(Precision + Recall)
F_Î² = (1+Î²Â²)Â·(PrecisionÂ·Recall)/(Î²Â²Â·Precision + Recall)
```

### Regression
```
MSE = (1/n)Î£(y_i - Å·_i)Â²
RMSE = âˆšMSE
MAE = (1/n)Î£|y_i - Å·_i|
RÂ² = 1 - (SS_res/SS_tot)
   = 1 - [Î£(y_i-Å·_i)Â²/Î£(y_i-È³)Â²]
```

---

## ğŸ”¢ Information Theory
```
Entropy: H(X) = -Î£ p(x) log p(x)
Joint Entropy: H(X,Y) = -Î£ p(x,y) log p(x,y)
Conditional Entropy: H(Y|X) = H(X,Y) - H(X)
Mutual Information: I(X;Y) = H(X) + H(Y) - H(X,Y)
KL Divergence: D_KL(P||Q) = Î£ p(x) log(p(x)/q(x))
Cross-Entropy: H(P,Q) = -Î£ p(x) log q(x)
```

---

## ğŸ² Probability Bounds

### Concentration Inequalities
```
Markov: P(X â‰¥ a) â‰¤ E[X]/a
Chebyshev: P(|X-Î¼| â‰¥ kÏƒ) â‰¤ 1/kÂ²
Hoeffding: P(|XÌ„-Î¼| â‰¥ Îµ) â‰¤ 2exp(-2nÎµÂ²)
```

---

**Use this as your formula reference during interviews and problem-solving!**
